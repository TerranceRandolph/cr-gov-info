{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USC CODE START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas  as gpd\n",
    "import os\n",
    "from sqlalchemy import engine\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import rasterio as rio\n",
    "from rasterio.features import dataset_features\n",
    "from osgeo import gdal\n",
    "import psycopg2\n",
    "from shapely import wkt\n",
    "from shapely.validation import make_valid\n",
    "import glob\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanbytes(B):\n",
    "    \"\"\"Return the given bytes as a human friendly KB, MB, GB, or TB string.\"\"\"\n",
    "    B = float(B)\n",
    "    KB = float(1024)\n",
    "    MB = float(KB ** 2) # 1,048,576\n",
    "    GB = float(KB ** 3) # 1,073,741,824\n",
    "    TB = float(KB ** 4) # 1,099,511,627,776\n",
    "\n",
    "    if B < KB:\n",
    "        return '{0} {1}'.format(B,'Bytes' if 0 == B > 1 else 'Byte')\n",
    "    elif KB <= B < MB:\n",
    "        return '{0:.2f} KB'.format(B / KB)\n",
    "    elif MB <= B < GB:\n",
    "        return '{0:.2f} MB'.format(B / MB)\n",
    "    elif GB <= B < TB:\n",
    "        return '{0:.2f} GB'.format(B / GB)\n",
    "    elif TB <= B:\n",
    "        return '{0:.2f} TB'.format(B / TB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_coverage(env, img_path, cov_path):\n",
    "    os.chdir(env)\n",
    "    cmd = f'gdaltindex {cov_path} {img_path}'\n",
    "    subprocess.call(cmd,shell=True)\n",
    "    # print(f'coverage created -- {cov_path}')\n",
    "    return(cov_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNC COVERAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/County_fips/fips_year'\n",
    "env = 'C:/Users/terra/anaconda3/envs/pygdal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = 'C:\\\\Users\\\\terra\\\\anaconda3\\\\envs\\\\pygdal'\n",
    "\n",
    "def create_coverages(folder):\n",
    "    # ------------------------------------------------- #\n",
    "    dfdict = {'img_name':[], 'fips':[],'dt_year':[],'img_num':[], 'img_size':[],\n",
    "            'meta_size':[],'meta_unit':[],'state':[],'meta_last_acc':[],'img_path':[]}\n",
    "    # ------------------------------------------------- #\n",
    "    dfdict_cov_geom = {'img_name':[], 'area_sqkm':[], 'shape':[]}\n",
    "    # ------------------------------------------------- #\n",
    "    for image in glob.glob(os.path.join(folder, '*.tif')):\n",
    "        image = image.replace('\\\\','/')\n",
    "        # ------------------------------------------------- #\n",
    "        img_path    = os.path.join(folder, image)\n",
    "        stats       = os.stat(img_path)\n",
    "        # temp path for coverage geojson\n",
    "        # create a temporary folder using library tempfile\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        temp_cov_path = os.path.join(temp_dir, 'temp_coverage.geojson')\n",
    "        # ------------------------------------------------- #\n",
    "        # get the image name without extension\n",
    "        img_name = image.split('\\\\')[-1].replace('.tif','')\n",
    "        # img_name    = os.path.splitext(image)[0] ; print(img_name)\n",
    "        imgsplit    = img_name.split('_')\n",
    "        # ------------------------------------------------- #\n",
    "        (fips, dt_year, img_num, img_size,\n",
    "            meta_size, meta_lastmod, meta_lastacc) = (imgsplit[0], imgsplit[1],\n",
    "                                                    imgsplit[3], imgsplit[5], humanbytes(round(stats.st_size)),\n",
    "                                                        datetime.fromtimestamp(stats.st_mtime),\n",
    "                                                        datetime.fromtimestamp(stats.st_atime))\n",
    "        # ------------------------------------------------- #\n",
    "        cov_path        = mk_coverage(env, img_path, temp_cov_path)\n",
    "        crs_string      = 'EPSG:3857'\n",
    "        gdf             = gpd.read_file(cov_path, crs=crs_string)\n",
    "        gdf             = gdf.dissolve()\n",
    "        gdf['geometry'] = gdf['geometry'].apply(make_valid)\n",
    "        gdf['area_sqkm']= gdf['geometry'].map(lambda p: p.area / 10**6)\n",
    "        sqkm            = int(round(sum(gdf.area_sqkm),2))\n",
    "        geom            = gdf['geometry'].values[0]\n",
    "        # ------------------------------------------------- #\n",
    "        dfdict['img_name'].append(str(img_name))      ;  dfdict['fips'].append(str(fips)),\n",
    "        dfdict['dt_year'].append(str(dt_year))        ;  dfdict['img_num'].append(str(img_num)),\n",
    "        dfdict['img_size'].append(str(img_size))      ;  dfdict['meta_size'].append(str(meta_size).replace(' MB',''))\n",
    "        dfdict['meta_last_acc'].append(str(meta_lastacc))  ;  dfdict['img_path'].append(str(img_path))\n",
    "        dfdict['meta_unit'].append('MB')                   ;  dfdict['state'].append('South Carolina')\n",
    "        # ------------------------------------------------- #\n",
    "        dfdict_cov_geom['img_name'].append(str(img_name))\n",
    "        dfdict_cov_geom['area_sqkm'].append(sqkm)#(int(round(sum(gdf.area_sqkm),2)))\n",
    "        dfdict_cov_geom['shape'].append(geom)\n",
    "    # merge both dictionaries on img_name\n",
    "    merge_dict = {**dfdict, **dfdict_cov_geom}\n",
    "    return(pd.DataFrame(merge_dict))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = create_coverages(folder)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=df['shape'])\n",
    "gdf = gdf.drop(columns=['shape'])\n",
    "gdf.to_file(os.path.join(folder,'cov/coverages.geojson'), driver=\"GeoJSON\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNC 8BIT MOSAIC UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of 8bit.webp files: ['45085_1980_179_0001_x_9', '45085_1980_179_0005_x_9', '45085_1980_179_0003_x_9']\n",
      "mosaic.vrt created\n",
      "D:/County_fips/fips_year/mosaic\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tiff_to_tile(folder):\n",
    "    bit_webp_ls     = []\n",
    "    need_process    = []\n",
    "    txt_ls          = []\n",
    "    # -------------------- #\n",
    "    # create a temp directory to store 8bit.webp files\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    # -------------------- #\n",
    "    # list of tiff files\n",
    "    tiff_ls = [t.replace('\\\\','/') for t in glob.glob(os.path.join(folder, '*.tif'))]\n",
    "    tiff_ls = [t.split('/')[-1].replace('.tif','') for t in tiff_ls]\n",
    "    # -------------------- #\n",
    "    \n",
    "    # read list from text file\n",
    "    with open(os.path.join(folder,'cov_8bit/bit_webp_ls.txt'), 'r') as f:\n",
    "        for line in f:\n",
    "            txt_ls.append(line.split(',')) \n",
    "    # flatten list\n",
    "    txt_ls = [item for sublist in txt_ls for item in sublist]  \n",
    "    # print(f'list from text file: {txt_ls}')\n",
    "    # print(f'list of tiff files: {tiff_ls}')\n",
    "    \n",
    "    # -------------------- #\n",
    "    \n",
    "    # if tiff names are not in txt file, add to need_process list\n",
    "    if txt_ls not in tiff_ls:\n",
    "        # append list of tiff files that are not in txt file\n",
    "        need_process.append([x for x in tiff_ls if x not in txt_ls])\n",
    "    # flatten list\n",
    "    need_process = [item for sublist in need_process for item in sublist]\n",
    "    # print(f'list of tiff files that need to be processing: {need_process}')\n",
    "    \n",
    "    # -------------------- #\n",
    "    \n",
    "    for image in need_process: \n",
    "        # folders and files var establishment\n",
    "        img_name = image.split('/')[-1].replace('.tif','')\n",
    "        org_tif  = os.path.join(folder, f'{img_name}.tif')\n",
    "        bit_webp   = os.path.join(temp_dir, f'{img_name}_8bit.webp')\n",
    "        # -------------------- #\n",
    "        # print(f'processing {img_name}...')\n",
    "        # convert tiff to 8bit webp format\n",
    "        cmd_8bit = f'gdal_translate -ot Byte -scale {org_tif} {bit_webp}'\n",
    "        # converte tiff to 8bit webp format\n",
    "        subprocess.call(cmd_8bit,shell=True)\n",
    "        # append to list of 8bit.webp files\n",
    "        bit_webp_ls.append(img_name)  \n",
    "        # print(f'{img_name} completed')\n",
    "    \n",
    "    # -------------------- #\n",
    "    \n",
    "    # overwrite current bit_webp_ls.txt & save list of 8bit.webp files to a text file for future use\n",
    "    with open(os.path.join(folder,'cov_8bit/bit_webp_ls.txt'), 'w') as f:\n",
    "        # write each item from the list to text file\n",
    "        for item in bit_webp_ls:\n",
    "            f.write(\"%s\" % item)\n",
    "    print(f'list of 8bit.webp files: {bit_webp_ls}') \n",
    "    ## SOLVE FOR REFRESHING THE LIST OF 8BIT.WEBP FILES ##\n",
    "    \n",
    "    ## FINAL VERSIION NEEDS VARS FOR 3 IN-YEAR FOLDERS ##\n",
    "    \n",
    "    # -------------------- #\n",
    "    # mosaic all 8bit.webp files in temp_dir\n",
    "    \n",
    "    # list of all 8bit.webp files in temp_dir\n",
    "    webp_files = glob.glob(os.path.join(temp_dir, '*.webp'))\n",
    "    tile_folder = os.path.join(folder,'mosaic').replace('\\\\','/')\n",
    "    # gdal mosaic all files in temp folder\n",
    "    cmd_mosaic = f'''gdalbuildvrt -overwrite -resolution average\n",
    "     -r nearest -input_file_list {webp_files} {tile_folder}/mosaic.vrt'''\n",
    "    subprocess.call(cmd_mosaic,shell=True) \n",
    "    print(f'mosaic.vrt created\\n{tile_folder}')\n",
    "    # print(webp_files)\n",
    "    \n",
    "    ## TROUBLESHOOT WHY gdalbuildvrt IS NOT WORKING ##\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "tiff_to_tile(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygdal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f005baf2d88abe9b2fc02dff8268a814339904da8d4bf3c1732217f71ee9099e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
